<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>redis-geo</title>
      <link href="/2024/11/13/redis-geo/"/>
      <url>/2024/11/13/redis-geo/</url>
      
        <content type="html"><![CDATA[<p>Redis 的 Geo 命令来处理地理位置数据。Redis 的 Geo 命令集可以存储地理位置（经纬度）数据，并支持基于地理位置的操作，例如计算两点之间的距离、查找附近的地点等，非常适合用于实现地理位置相关的功能，比如地图定位、附近的商家等。<br>使用场景</p><ul><li>查找附近地点：如用户附近的商家、酒店、加油站等。</li><li>计算距离：计算两个地点之间的距离。</li><li>定位标记：保存多个地点的地理位置和信息。<br>Redis Geo 基本命令和示例<br>以下是 Redis Geo 命令的示例，包括存储地理位置数据、计算距离和查找附近地点等。</li></ul><ol><li>添加地理位置数据 - GEOADD<br>使用 GEOADD 命令将地点的经纬度数据添加到 Redis 中。</li></ol><h1 id="将多个地点添加到-“places”-键下"><a href="#将多个地点添加到-“places”-键下" class="headerlink" title="将多个地点添加到 “places” 键下"></a>将多个地点添加到 “places” 键下</h1><p>GEOADD places 116.403963 39.915119 “Tiananmen”  # 天安门的经纬度<br>GEOADD places 116.397128 39.916527 “ForbiddenCity”  # 故宫的经纬度<br>GEOADD places 116.414117 39.906647 “Wangfujing”  # 王府井的经纬度</p><ol start="2"><li>获取地点的经纬度 - GEOPOS<br>使用 GEOPOS 可以获取存储的地点的经纬度。<br>GEOPOS places “Tiananmen”</li></ol><h1 id="返回-116-403963-39-915119"><a href="#返回-116-403963-39-915119" class="headerlink" title="返回: [116.403963, 39.915119]"></a>返回: [116.403963, 39.915119]</h1><ol start="3"><li>计算两个地点之间的距离 - GEODIST<br>使用 GEODIST 命令计算两个地点之间的距离。可以指定单位：米（m）、千米（km）、英里（mi）、英尺（ft）。<br>GEODIST places “Tiananmen” “ForbiddenCity” km</li></ol><h1 id="返回-距离（千米），例如-0-6-表示-600-米左右"><a href="#返回-距离（千米），例如-0-6-表示-600-米左右" class="headerlink" title="返回: 距离（千米），例如 0.6 表示 600 米左右"></a>返回: 距离（千米），例如 0.6 表示 600 米左右</h1><ol start="4"><li>查找指定范围内的地点 - GEORADIUS<br>使用 GEORADIUS 命令查找某个点一定范围内的所有地点。这非常适合实现“查找附近的商家”功能。</li></ol><h1 id="查找天安门-2-公里范围内的所有地点"><a href="#查找天安门-2-公里范围内的所有地点" class="headerlink" title="查找天安门 2 公里范围内的所有地点"></a>查找天安门 2 公里范围内的所有地点</h1><p>GEORADIUS places 116.403963 39.915119 2 km</p><h1 id="返回-“Tiananmen”-“ForbiddenCity”"><a href="#返回-“Tiananmen”-“ForbiddenCity”" class="headerlink" title="返回: [ “Tiananmen”, “ForbiddenCity” ]"></a>返回: [ “Tiananmen”, “ForbiddenCity” ]</h1><p>可以使用 WITHDIST、WITHCOORD 等参数来显示额外信息：<br>GEORADIUS places 116.403963 39.915119 2 km WITHDIST WITHCOORD</p><ol start="5"><li>查找某地点附近的地点 - GEORADIUSBYMEMBER<br>使用 GEORADIUSBYMEMBER 命令可以指定一个存储的地点，并查找该地点周围一定范围内的其他地点。</li></ol><h1 id="查找-“Tiananmen”-附近-2-公里内的地点"><a href="#查找-“Tiananmen”-附近-2-公里内的地点" class="headerlink" title="查找 “Tiananmen” 附近 2 公里内的地点"></a>查找 “Tiananmen” 附近 2 公里内的地点</h1><p>GEORADIUSBYMEMBER places “Tiananmen” 2 km WITHDIST</p><h1 id="返回-“Tiananmen”-“ForbiddenCity”-1"><a href="#返回-“Tiananmen”-“ForbiddenCity”-1" class="headerlink" title="返回: [ “Tiananmen”, “ForbiddenCity” ]"></a>返回: [ “Tiananmen”, “ForbiddenCity” ]</h1><ol start="6"><li>获取地点的 GeoHash 值 - GEOHASH<br>GeoHash 是一种将地理位置编码为字符串的方法。可以使用 GEOHASH 获取存储的地点的 GeoHash 值。<br>GEOHASH places “Tiananmen”</li></ol><h1 id="返回-“wx4g09x7z”"><a href="#返回-“wx4g09x7z”" class="headerlink" title="返回: [“wx4g09x7z”]"></a>返回: [“wx4g09x7z”]</h1><p>实战场景示例<br>假设我们有一个商家的位置信息，用户可以查找附近的商家：<br>1.商家位置添加<br>：<br>GEOADD stores 116.4015 39.9123 “Store_A”<br>GEOADD stores 116.4058 39.9163 “Store_B”<br>GEOADD stores 116.4123 39.9072 “Store_C”</p><p>2.查找用户附近的商家<br>：<br>假设用户位置为 116.4039（经度）、39.9151（纬度），查找 1 公里范围内的商家：<br>GEORADIUS stores 116.4039 39.9151 1 km WITHDIST</p><p>3.计算两个商家之间的距离<br>：<br>计算 Store_A 和 Store_B 之间的距离：<br>GEODIST stores “Store_A” “Store_B” km</p><p>总结<br>Redis Geo 命令提供了强大的地理位置处理功能，非常适合用于实现地图服务、位置检索、距离计算等场景。通过简单的命令，你可以快速实现“附近的地点”查询等功能，适合社交平台、电子商务等应用场景。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis-geo </tag>
            
            <tag> 距离计算 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis-hash</title>
      <link href="/2024/11/13/redis-hash/"/>
      <url>/2024/11/13/redis-hash/</url>
      
        <content type="html"><![CDATA[<p>Redis 的 Hash 是一种键值对的集合，非常适合存储对象或结构化数据。每个 Hash 键下可以包含多个字段和值，结构类似于 Python 的字典或 JSON 对象。Hash 非常适合在 Redis 中存储用户信息、配置数据等场景。<br>使用场景和示例<br>以下是几个 Redis Hash 的典型使用场景和示例：</p><ol><li>存储用户信息<br>在社交应用中，可以使用 Hash 来存储用户的个人信息，如用户名、邮箱、年龄等。这样可以方便地对某个字段进行更新，而无需重新存储整个对象。<br>示例：存储用户信息</li></ol><h1 id="添加用户信息"><a href="#添加用户信息" class="headerlink" title="添加用户信息"></a>添加用户信息</h1><p>HSET user:1001 username “Alice” email “<a href="mailto:&#97;&#108;&#105;&#99;&#x65;&#x40;&#x65;&#120;&#97;&#109;&#x70;&#108;&#101;&#46;&#x63;&#111;&#109;">&#97;&#108;&#105;&#99;&#x65;&#x40;&#x65;&#120;&#97;&#109;&#x70;&#108;&#101;&#46;&#x63;&#111;&#109;</a>“ age “30”<br>HSET user:1002 username “Bob” email “<a href="mailto:&#98;&#111;&#98;&#x40;&#101;&#x78;&#x61;&#109;&#x70;&#x6c;&#101;&#x2e;&#99;&#x6f;&#x6d;">&#98;&#111;&#98;&#x40;&#101;&#x78;&#x61;&#109;&#x70;&#x6c;&#101;&#x2e;&#99;&#x6f;&#x6d;</a>“ age “25”</p><h1 id="获取用户-1001-的所有信息"><a href="#获取用户-1001-的所有信息" class="headerlink" title="获取用户 1001 的所有信息"></a>获取用户 1001 的所有信息</h1><p>HGETALL user:1001</p><h1 id="获取用户-1001-的邮箱"><a href="#获取用户-1001-的邮箱" class="headerlink" title="获取用户 1001 的邮箱"></a>获取用户 1001 的邮箱</h1><p>HGET user:1001 email</p><h1 id="更新用户-1002-的年龄"><a href="#更新用户-1002-的年龄" class="headerlink" title="更新用户 1002 的年龄"></a>更新用户 1002 的年龄</h1><p>HSET user:1002 age “26”</p><ol start="2"><li>电商中的购物车<br>在电商应用中，可以使用 Hash 存储购物车数据。Hash 的字段可以是商品 ID，值可以是商品数量。这样可以高效地管理每个用户的购物车内容。<br>示例：管理购物车</li></ol><h1 id="用户-1001-添加商品到购物车"><a href="#用户-1001-添加商品到购物车" class="headerlink" title="用户 1001 添加商品到购物车"></a>用户 1001 添加商品到购物车</h1><p>HSET cart:1001 item:2001 2   # 2 件商品 ID 为 2001 的商品<br>HSET cart:1001 item:2002 1   # 1 件商品 ID 为 2002 的商品</p><h1 id="获取用户-1001-的购物车信息"><a href="#获取用户-1001-的购物车信息" class="headerlink" title="获取用户 1001 的购物车信息"></a>获取用户 1001 的购物车信息</h1><p>HGETALL cart:1001</p><h1 id="增加商品数量"><a href="#增加商品数量" class="headerlink" title="增加商品数量"></a>增加商品数量</h1><p>HINCRBY cart:1001 item:2001 1  # 将商品 2001 的数量增加 1</p><h1 id="删除商品"><a href="#删除商品" class="headerlink" title="删除商品"></a>删除商品</h1><p>HDEL cart:1001 item:2002</p><ol start="3"><li>网站配置信息<br>在网站或应用中，有时需要一组全局的配置信息，例如站点名称、主题、管理员邮箱等。可以使用 Redis Hash 存储这些配置信息，并方便地对其进行动态更新。<br>示例：存储网站配置</li></ol><h1 id="设置网站配置"><a href="#设置网站配置" class="headerlink" title="设置网站配置"></a>设置网站配置</h1><p>HSET site:config site_name “MyWebsite” theme “dark” admin_email “<a href="mailto:&#x61;&#x64;&#x6d;&#105;&#x6e;&#x40;&#x6d;&#x79;&#x77;&#x65;&#x62;&#x73;&#105;&#116;&#x65;&#46;&#x63;&#111;&#109;">&#x61;&#x64;&#x6d;&#105;&#x6e;&#x40;&#x6d;&#x79;&#x77;&#x65;&#x62;&#x73;&#105;&#116;&#x65;&#46;&#x63;&#111;&#109;</a>“</p><h1 id="获取网站的所有配置信息"><a href="#获取网站的所有配置信息" class="headerlink" title="获取网站的所有配置信息"></a>获取网站的所有配置信息</h1><p>HGETALL site:config</p><h1 id="更新配置，比如修改主题"><a href="#更新配置，比如修改主题" class="headerlink" title="更新配置，比如修改主题"></a>更新配置，比如修改主题</h1><p>HSET site:config theme “light”</p><ol start="4"><li>实时统计数据<br>在实时统计应用中，可以使用 Hash 存储多项数据，例如页面访问量、活跃用户数等，每个字段代表一种统计指标。<br>示例：统计页面访问量</li></ol><h1 id="初始化访问量统计"><a href="#初始化访问量统计" class="headerlink" title="初始化访问量统计"></a>初始化访问量统计</h1><p>HSET page:stats homepage 100 aboutpage 50 contactpage 30</p><h1 id="增加访问量"><a href="#增加访问量" class="headerlink" title="增加访问量"></a>增加访问量</h1><p>HINCRBY page:stats homepage 1  # 首页访问量增加 1<br>HINCRBY page:stats aboutpage 2 # 关于页面访问量增加 2</p><h1 id="获取所有页面访问量"><a href="#获取所有页面访问量" class="headerlink" title="获取所有页面访问量"></a>获取所有页面访问量</h1><p>HGETALL page:stats</p><ol start="5"><li>缓存对象或数据库行<br>将数据库中的行数据缓存在 Redis 中。对于一条数据库记录，可以将其转换为 Hash 存储，并使用主键作为 Hash 的键名。<br>示例：缓存数据库记录<br>假设有一个用户表 User，其中用户 ID 为 1001 的记录包含用户名、邮箱和年龄等字段。可以将其缓存到 Redis 中：</li></ol><h1 id="将数据库记录缓存到-Redis"><a href="#将数据库记录缓存到-Redis" class="headerlink" title="将数据库记录缓存到 Redis"></a>将数据库记录缓存到 Redis</h1><p>HSET user:1001 username “Alice” email “<a href="mailto:&#97;&#108;&#105;&#x63;&#x65;&#x40;&#x65;&#x78;&#x61;&#x6d;&#112;&#108;&#101;&#46;&#x63;&#111;&#109;">&#97;&#108;&#105;&#x63;&#x65;&#x40;&#x65;&#x78;&#x61;&#x6d;&#112;&#108;&#101;&#46;&#x63;&#111;&#109;</a>“ age “30”</p><h1 id="获取缓存记录"><a href="#获取缓存记录" class="headerlink" title="获取缓存记录"></a>获取缓存记录</h1><p>HGETALL user:1001</p><p>总结<br>Redis Hash 是一种高效的存储结构，适合存储结构化的对象数据，比如用户信息、购物车、配置项等。通过 HGET、HSET、HINCRBY 等命令，用户可以方便地获取、更新某些字段的值，在访问频繁的数据场景下尤其适合使用。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis-hash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis-set</title>
      <link href="/2024/11/13/redis-set/"/>
      <url>/2024/11/13/redis-set/</url>
      
        <content type="html"><![CDATA[<p>在 Redis 中，Set 是一种无序集合数据结构，可以高效地存储唯一的值，并支持交集、并集、差集等操作，非常适合实现共同好友、共同关注等功能。以下是一些关于 Redis Set 的操作和示例：<br>基本命令和用法<br>1.添加元素</p><ul><li>SADD将一个或多个元素添加到集合中，如果元素已存在，则会自动忽略。<br>SADD friends:user_a “Alice” “Bob” “Charlie” “David”<br>SADD friends:user_b “Charlie” “David” “Eve” “Frank”<br>2.查看集合中的元素</li><li>SMEMBERS返回集合中的所有元素。<br>SMEMBERS friends:user_a<br>SMEMBERS friends:user_b<br>3.求交集</li><li>SINTER找出两个集合的交集（共同好友）。<br>SINTER friends:user_a friends:user_b<br>4.求并集</li><li>SUNION返回两个集合的并集（所有好友）。<br>SUNION friends:user_a friends:user_b<br>5.求差集</li><li>SDIFF返回在第一个集合中有但在其他集合中没有的元素。<br>SDIFF friends:user_a friends:user_b  # 返回 user_a 独有的好友<br>SDIFF friends:user_b friends:user_a  # 返回 user_b 独有的好友</li></ul><p>6.获取集合元素个数</p><ul><li>SCARD获取集合中元素的数量。<br>SCARD friends:user_a<br>SCARD friends:user_b</li></ul><p>7.检查元素是否存在</p><ul><li>SISMEMBER判断某个元素是否在集合中。<br>SISMEMBER friends:user_a “Alice”  # 返回 1 表示存在，0 表示不存在</li></ul><p>实际示例：共同好友、共同关注<br>假设我们想找出 user_a 和 user_b 的共同好友：</p><h1 id="添加用户的好友"><a href="#添加用户的好友" class="headerlink" title="添加用户的好友"></a>添加用户的好友</h1><p>SADD friends:user_a “Alice” “Bob” “Charlie” “David”<br>SADD friends:user_b “Charlie” “David” “Eve” “Frank”</p><h1 id="找出共同好友"><a href="#找出共同好友" class="headerlink" title="找出共同好友"></a>找出共同好友</h1><p>SINTER friends:user_a friends:user_b</p><h1 id="输出-“Charlie”-“David”"><a href="#输出-“Charlie”-“David”" class="headerlink" title="输出: “Charlie”, “David”"></a>输出: “Charlie”, “David”</h1><p>并集操作示例</p><h1 id="获取所有好友（并集）"><a href="#获取所有好友（并集）" class="headerlink" title="获取所有好友（并集）"></a>获取所有好友（并集）</h1><p>SUNION friends:user_a friends:user_b</p><h1 id="输出-“Alice”-“Bob”-“Charlie”-“David”-“Eve”-“Frank”"><a href="#输出-“Alice”-“Bob”-“Charlie”-“David”-“Eve”-“Frank”" class="headerlink" title="输出: “Alice”, “Bob”, “Charlie”, “David”, “Eve”, “Frank”"></a>输出: “Alice”, “Bob”, “Charlie”, “David”, “Eve”, “Frank”</h1><p>差集操作示例</p><h1 id="获取仅属于-user-a-的好友"><a href="#获取仅属于-user-a-的好友" class="headerlink" title="获取仅属于 user_a 的好友"></a>获取仅属于 user_a 的好友</h1><p>SDIFF friends:user_a friends:user_b</p><h1 id="输出-“Alice”-“Bob”"><a href="#输出-“Alice”-“Bob”" class="headerlink" title="输出: “Alice”, “Bob”"></a>输出: “Alice”, “Bob”</h1><p>常见应用场景<br>1.社交网络：计算共同好友、共同关注、共同兴趣等。<br>2.推荐系统：基于用户关注、收藏等数据，快速找到共同的偏好。<br>3.权限管理：将用户的权限存入集合中，可以快速进行权限的交集和差集计算。<br>Redis Set 提供的高效集合操作，可以极大地简化和加速社交网络中的关系计算等场景。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 共同好友等 </tag>
            
            <tag> redis-set </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql</title>
      <link href="/2024/11/08/mysql/"/>
      <url>/2024/11/08/mysql/</url>
      
        <content type="html"><![CDATA[<p>一、MySQL 的核心架构<br>MySQL 的架构可以分为三层：</p><p>连接层：</p><p>主要负责与客户端的连接和认证，包括处理权限验证、安全性检查。<br>连接层使用缓存池管理会话和连接。每个连接会话都为用户提供独立的查询环境。<br>服务层：</p><p>处理所有逻辑操作，如 SQL 解析、查询优化、缓存、存储过程等。<br>查询解析：接收 SQL 语句并将其转换为执行计划。<br>查询优化：MySQL 使用查询优化器生成优化的执行计划。<br>缓存管理：通过查询缓存提升查询速度。<br>存储引擎 API：服务层通过 API 与底层存储引擎交互。<br>存储引擎层：</p><p>MySQL 支持多种存储引擎 (如 InnoDB、MyISAM、Memory、CSV 等)，提供不同的数据存储和管理方式。<br>InnoDB 是 MySQL 默认的存储引擎，支持事务、行级锁和外键约束，非常适合高并发和数据一致性要求高的应用。<br>二、MySQL 的存储引擎<br>MySQL 提供多种存储引擎，可以根据需求选择不同的存储引擎。常见的存储引擎有：</p><p>InnoDB：</p><p>支持 ACID 事务和行级锁。<br>使用多版本并发控制 (MVCC)，确保数据的一致性和并发性。<br>使用 UNDO LOG 和 REDO LOG 记录事务操作，实现数据回滚和故障恢复。<br>支持外键约束，适合 OLTP (联机事务处理) 场景。<br>MyISAM：</p><p>不支持事务和外键，采用表级锁。<br>适合读密集型和数据分析的应用，常用于 OLAP 场景。<br>支持全文索引，可以快速执行全文搜索。<br>Memory：</p><p>数据存储在内存中，速度快但数据不持久。<br>适用于对数据持久性要求不高的临时表、缓存等应用。<br>其他引擎：</p><p>CSV：数据以 CSV 文件形式存储，适合数据导入导出。<br>Archive：适合存储大量历史数据，具有高压缩率。<br>三、MySQL 的事务管理<br>事务是确保数据库操作完整性和一致性的关键机制。MySQL 事务特性包括：</p><p>ACID 特性：</p><p>Atomicity（原子性）：事务中的操作要么全部执行成功，要么全部回滚。<br>Consistency（一致性）：事务执行后数据库状态保持一致。<br>Isolation（隔离性）：并发事务互不影响，避免脏读、幻读等问题。<br>Durability（持久性）：事务提交后，数据应永久保留。<br>事务隔离级别：</p><p>Read Uncommitted：允许脏读、不可重复读和幻读。<br>Read Committed：避免脏读，但可能会出现不可重复读和幻读。<br>Repeatable Read：MySQL 默认的隔离级别，避免脏读和不可重复读，但可能出现幻读。<br>Serializable：最高的隔离级别，避免所有并发问题，但效率较低。<br>事务日志：</p><p>Redo Log：记录已提交的事务用于恢复，保证数据持久性。<br>Undo Log：记录未提交的修改，用于回滚操作，支持 MVCC。<br>四、MySQL 的锁机制<br>MySQL 采用锁机制控制并发操作，避免数据冲突。常见的锁类型有：</p><p>表级锁：锁住整个表，效率高但并发性差，MyISAM 引擎使用表级锁。</p><p>行级锁：锁住数据行，适合高并发应用，InnoDB 引擎使用行级锁。</p><p>MVCC（多版本并发控制）：InnoDB 通过 Undo Log 提供一致性读操作，使不同事务可以读取各自快照数据。</p><p>五、MySQL 的优化策略<br>查询优化：</p><p>索引：创建合理的索引可以加速查询。常见索引包括 B+ 树索引、全文索引等。<br>查询缓存：MySQL 可以缓存查询结果，但 MySQL 8.0 已取消此功能。<br>分区表：将大表分区，可以减少单次扫描的数据量，提高查询效率。<br>配置优化：</p><p>根据服务器内存、CPU 和存储等资源，调整 innodb_buffer_pool_size、query_cache_size 等参数。<br>使用 SSD 作为数据存储，提高读写速度。<br>事务优化：</p><p>减少事务持续时间，避免长事务锁定资源。<br>使用批量操作而不是逐条执行，提高事务效率。<br>架构优化：</p><p>主从复制：配置主从复制实现读写分离，提高读性能。<br>分库分表：在数据量过大的场景，将数据拆分到多个库和表中。<br>六、常用 SQL 查询语法<br>查询数据：</p><p>sql<br>复制代码<br>SELECT column1, column2 FROM table WHERE condition ORDER BY column LIMIT n;<br>插入数据：</p><p>sql<br>复制代码<br>INSERT INTO table (column1, column2) VALUES (value1, value2);<br>更新数据：</p><p>sql<br>复制代码<br>UPDATE table SET column1 &#x3D; value1 WHERE condition;<br>删除数据：</p><p>sql<br>复制代码<br>DELETE FROM table WHERE condition;<br>七、MySQL 日常管理<br>备份：</p><p>使用 mysqldump 命令进行逻辑备份。<br>配置定期备份策略确保数据安全。<br>用户权限管理：</p><p>sql<br>复制代码<br>CREATE USER ‘username‘@’host’ IDENTIFIED BY ‘password’;<br>GRANT ALL PRIVILEGES ON database.* TO ‘username‘@’host’;<br>FLUSH PRIVILEGES;<br>监控：</p><p>配置 performance_schema 监控查询性能、锁等待等。<br>使用 SHOW ENGINE INNODB STATUS; 获取 InnoDB 运行状态，帮助调优。<br>总结<br>MySQL 是高效、灵活的数据库管理系统，适用于多种应用场景。熟悉 MySQL 的架构、事务管理、锁机制以及优化策略有助于发挥 MySQL 的最大性能。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql事务</title>
      <link href="/2024/11/08/mysql%E4%BA%8B%E5%8A%A1/"/>
      <url>/2024/11/08/mysql%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<ol><li>支持 ACID 事务和行级锁<br>ACID 事务<br>MySQL 中的事务 (Transaction) 是一组逻辑操作的集合，这些操作要么全都执行成功，要么全都失败回滚，以保证数据库的一致性。ACID 是事务的四大基本特性：</li></ol><p>原子性 (Atomicity)：事务中的所有操作是一个不可分割的原子单位，要么全部执行成功，要么全部回滚。在 MySQL 中，通过 UNDO LOG 实现回滚机制来支持原子性。</p><p>一致性 (Consistency)：事务执行的前后，数据库状态必须保持一致，即约束和规则必须得到满足。InnoDB 使用锁机制和外键约束确保一致性。</p><p>隔离性 (Isolation)：并发事务之间互不干扰，MySQL 提供了不同的隔离级别以控制并发问题，如脏读、不可重复读和幻读。通过行级锁和 MVCC 支持高隔离性。</p><p>持久性 (Durability)：事务提交后，结果是永久性的，即使系统崩溃或断电，数据也不会丢失。InnoDB 通过 REDO LOG 和事务日志的写盘操作来确保数据持久性。</p><p>行级锁<br>MySQL InnoDB 引擎使用行级锁 (Row-level Lock) 而不是表级锁，以提高并发性能：</p><p>行级锁的优点：只锁定需要操作的行数据，允许其他事务并行访问不同的行，这样能够显著提高系统的并发性。</p><p>行级锁的实现：InnoDB 使用多版本并发控制 (MVCC) 和索引来实现行锁。它依赖于索引来识别被锁的行，因此最好在查询中使用索引条件，否则会锁定整个表。</p><ol start="2"><li>多版本并发控制 (MVCC)<br>MVCC 的概念<br>多版本并发控制 (MVCC) 是一种数据库并发控制机制，它允许数据库同时处理多个事务而不会产生冲突。MVCC 通过保存数据的多个版本，实现“快照隔离”：</li></ol><p>快照读：事务读取的不是最新版本的数据，而是事务开始时的数据快照。<br>一致性读：对于 SELECT 语句，InnoDB 引擎会选择最符合事务一致性要求的数据版本。<br>MVCC 的实现<br>InnoDB 通过使用隐藏列 DB_TRX_ID（表示事务 ID）和 DB_ROLL_PTR（回滚指针）来实现 MVCC：</p><p>事务 ID (DB_TRX_ID)：每次事务开始时分配唯一的 ID，用于标识事务对记录的操作。<br>回滚指针 (DB_ROLL_PTR)：指向该行的 UNDO LOG 记录。如果某条记录被事务修改了，UNDO LOG 会保存修改前的旧值。这样，如果一个事务想读取之前版本的数据，就可以通过 DB_ROLL_PTR 指针查找并读取到过去的版本。<br>在读写操作时，MySQL 可以通过这些隐藏列判断数据的版本是否符合当前事务的隔离级别，从而避免加锁操作，提高了数据库的并发处理能力。</p><ol start="3"><li>UNDO LOG 和 REDO LOG<br>UNDO LOG<br>UNDO LOG 是 InnoDB 用于回滚和 MVCC 的日志，它记录了数据修改前的状态。UNDO LOG 主要有两个作用：</li></ol><p>事务回滚：如果事务需要回滚，InnoDB 可以根据 UNDO LOG 将数据恢复到事务执行前的状态，从而保证事务的原子性。</p><p>多版本控制 (MVCC)：UNDO LOG 提供数据的历史版本，通过回滚指针 (DB_ROLL_PTR) 指向旧数据，为 MVCC 提供支持。每个事务可以通过 UNDO LOG 获取该行在事务开始时的快照数据，实现一致性读。</p><p>UNDO LOG 的类型主要有两种：</p><p>插入类型 (Insert Undo)：用于插入新数据时，记录插入之前的数据状态。只在事务未提交时需要回滚。<br>更新类型 (Update Undo)：记录数据更新前的状态，用于事务回滚和 MVCC。<br>UNDO LOG 一般存储在内存中，但可能会因需要或内存不足而被写入磁盘。</p><p>REDO LOG<br>REDO LOG 是 MySQL InnoDB 的重做日志，用于记录已提交事务的修改操作，确保数据的持久性。REDO LOG 的作用主要是：</p><p>崩溃恢复：在系统崩溃或断电后，通过 REDO LOG 重做提交的事务，从而恢复数据库。</p><p>持久性：在事务提交时，InnoDB 会先将 REDO LOG 写入磁盘，即使主数据文件未更新，REDO LOG 也确保了事务的持久性。</p><p>REDO LOG 由两个文件组成，记录了数据页的更改。每当有修改操作时，InnoDB 会将变更写入 REDO LOG，并将其持久化到磁盘，而不必立即修改数据文件。这样可以减少磁盘 I&#x2F;O，提高数据库性能。</p><p>两阶段提交：为了确保数据一致性，MySQL 使用了两阶段提交机制，即当事务执行时，先写入 REDO LOG，然后更新主数据文件，这样即使系统崩溃也能通过重做日志恢复到一致状态。<br>4. UNDO LOG 和 REDO LOG 的区别<br>特性UNDO LOGREDO LOG<br>主要作用支持事务回滚和 MVCC支持事务的持久性和崩溃恢复<br>记录内容修改前的数据快照修改后的数据操作<br>写入时机事务开始时或修改数据时事务提交前<br>数据保存位置内存中，必要时写入磁盘持久化存储在磁盘中<br>是否持久化否，只在回滚和 MVCC 使用是，用于崩溃恢复和持久化<br>小结<br>MySQL 的 ACID 特性和高并发控制依赖于事务管理和日志机制。InnoDB 通过行级锁和 MVCC 提高并发性，通过 UNDO LOG 提供回滚和一致性读，使用 REDO LOG 实现事务持久性和崩溃恢复。这些机制共同确保了数据库在高并发环境下的性能和数据一致性。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>gpu-export-2</title>
      <link href="/2024/11/08/gpu-export-2/"/>
      <url>/2024/11/08/gpu-export-2/</url>
      
        <content type="html"><![CDATA[<p>M-29 gpu监控：prometheus方案详解<br>gpu监控：prometheus方案详解<br>本文档基于开源项目<a href="https://github.com/utkuozdemir/nvidia_gpu_exporter">nvidia_gpu_exporter</a>实现gpu监控<br>参考文档：<a href="https://zhuanlan.zhihu.com/p/544321724?utm_id=0">https://zhuanlan.zhihu.com/p/544321724?utm_id=0</a></p><p>常用监控项统计周期：<br>#按显卡uuid匹配，查询指定周期内所有gpu的平均使用率<br>avg(avg_over_time(nvidia_smi_utilization_gpu_ratio{uuid&#x3D;~”.*”}[1d:1d]))</p><p>#按job任务名匹配,查询指定周期内所有显卡显存的平均使用率<br>avg(avg_over_time(nvidia_smi_memory_used_bytes{job&#x3D;~”zj_gpu”}[1d:1d])&#x2F;1024&#x2F;1024&#x2F;1024)&#x2F;32*100</p><p>常用监控项统计实时：<br>nvidia_smi_utilization_gpu_ratio: GPU利用率，单位是百分比：avg(nvidia_smi_utilization_gpu_ratio{uuid&#x3D;<del>“.*”})<br>显存平均使用率：avg(nvidia_smi_memory_used_bytes{uuid&#x3D;</del>“.<em>“}&#x2F;1024&#x2F;1024&#x2F;1024)&#x2F;32</em>100</p><p>厂区监控：<br>avg(avg_over_time(nvidia_smi_utilization_gpu_ratio{job&#x3D;<del>“cqjk_gpu_prod”}[1d:1d]))<br>avg(avg_over_time(nvidia_smi_memory_used_bytes{job&#x3D;</del>“cqjk_gpu_prod”}[1d:1d])&#x2F;1024&#x2F;1024&#x2F;1024)&#x2F;16<em>100<br>avg(nvidia_smi_memory_used_bytes{job&#x3D;~”cqjk_gpu_prod”}&#x2F;1024&#x2F;1024&#x2F;1024)&#x2F;16</em>100</p><p>一、在gpu服务器上部署nvidia_gpu_exporter<br>1、获取nvidia_gpu_exporter<br>wget <a href="https://github.com/utkuozdemir/nvidia_gpu_exporter/releases/download/v0.5.0/nvidia_gpu_exporter_0.5.0_linux_x86_64.tar.gz">https://github.com/utkuozdemir/nvidia_gpu_exporter/releases/download/v0.5.0/nvidia_gpu_exporter_0.5.0_linux_x86_64.tar.gz</a></p><p>2、运行nvidia_gpu_exporter<br>临时：<br>nohup .&#x2F;nvidia_gpu_exporter &gt;&#x2F;var&#x2F;log&#x2F;gpu-exporter.log 2&gt;&amp;1 &amp;</p><p>自启动：vim gpu_exporter.service<br>[Unit]<br>Description&#x3D;Nvidia GPU Exporter<br>After&#x3D;network-online.target</p><p>[Service]<br>Type&#x3D;simple</p><p>User&#x3D;root<br>Group&#x3D;root</p><p>ExecStart&#x3D;&#x2F;opt&#x2F;nvidia_gpu_exporter  #nvidia_gpu_exporter二进制执行文件存放路径</p><p>SyslogIdentifier&#x3D;nvidia_gpu_exporter</p><p>Restart&#x3D;always<br>RestartSec&#x3D;1</p><p>NoNewPrivileges&#x3D;yes</p><p>ProtectHome&#x3D;yes<br>ProtectSystem&#x3D;strict<br>ProtectControlGroups&#x3D;true<br>ProtectKernelModules&#x3D;true<br>ProtectKernelTunables&#x3D;yes<br>ProtectHostname&#x3D;yes<br>ProtectKernelLogs&#x3D;yes<br>ProtectProc&#x3D;yes</p><p>[Install]<br>WantedBy&#x3D;multi-user.target</p><p>3、检测监控数据<br>项目运行后会自动监听:9835端口<br>尝试curl本机来查看是否正常获取到监控数据<br>curl localhost:9835&#x2F;metrics</p><p>二、接入prometheus监控<br>在prometheus.yml中添加exporter地址</p><ul><li>job_name: ‘zj_gpu’<br>static_configs:<ul><li>targets: [‘10.0.1.1:9835’]<br>labels:<br>  gpu: ‘Tesla_V100’<br>  app: ‘gpu-exporter’</li></ul></li></ul><p>三、常用监控指标<br>指标名含义nvidia_smi_utilization_gpu_ratioGPU使用率nvidia_smi_memory_used_bytesGPU显存使用量nvidia_smi_memory_total_bytesGPU显存总量nvidia_smi_temperature_gpuGPU温度<br>prometheus的常用聚合操作符<br>sum                     在维度上求和<br>max                     在维度上求最大值<br>min                     在维度上求最小值<br>avg                     在维度上求平均值<br>stddev                  求标准差<br>stdvar                  求方差<br>count                   统计向量元素的个数<br>count_values            统计相同数据值的元素数量<br>bottomk                 样本值第k个最小值<br>topk                    样本值第k个最大值<br>quantile                统计分位数</p><p>以下函数允许随着时间的推移聚合给定范围向量的每个序列，并返回具有每个序列聚合结果的即时向量：</p><ul><li>avg_over_time(range-vector)：指定间隔内所有点的平均值。</li><li>min_over_time(range-vector)：指定间隔中所有点的最小值。</li><li>max_over_time(range-vector)：指定间隔内所有点的最大值。</li><li>sum_over_time(range-vector)：指定时间间隔内所有值的总和。<br>四、grafana模板监控<br>grafana dashboard官方有开源适用于nvidia_gpu_exporter面板ID:14574<br>*** 注意：版本大于 8.1， 推荐: grafana9.+</li></ul><p>#官方模板功能不全，建议添加：GPU平均使用率面板<br>新建granfna表盘 类型：Gauge<br>Query：<br>A: avg(nvidia_smi_utilization_gpu_ratio{uuid&#x3D;~”.*”})<br>Unit：Percent(0.0-1.0)<br>效果：</p><p>五、promql监控项列举<br>nvidia_gpu_exporter_build_info: 显示 NVIDIA GPU Exporter 构建信息（版本，修订，分支和构建的Go语言版本）。<br>nvidia_smi_accounting_buffer_size: 记账模式的缓冲区大小。<br>nvidia_smi_accounting_mode: 显示 GPU 记账模式的状态。<br>nvidia_smi_clocks_applications_graphics_clock_hz: 应用程序的图形处理器时钟频率。<br>nvidia_smi_clocks_applications_memory_clock_hz: 应用程序的内存时钟频率。<br>nvidia_smi_clocks_current_graphics_clock_hz: 当前的图形处理器时钟频率。<br>nvidia_smi_clocks_current_memory_clock_hz: 当前的内存时钟频率。<br>nvidia_smi_clocks_current_sm_clock_hz: 当前的流多处理器(SM)时钟频率。<br>nvidia_smi_clocks_current_video_clock_hz: 当前的视频时钟频率。<br>nvidia_smi_clocks_default_applications_graphics_clock_hz: 默认应用程序的图形处理器时钟频率。<br>nvidia_smi_clocks_default_applications_memory_clock_hz: 默认应用程序的内存时钟频率。<br>nvidia_smi_clocks_max_graphics_clock_hz: 图形处理器的最大时钟频率。<br>nvidia_smi_clocks_max_memory_clock_hz: 内存的最大时钟频率。<br>nvidia_smi_clocks_max_sm_clock_hz: 流多处理器(SM)的最大时钟频率。<br>nvidia_smi_clocks_throttle_reasons_*: 显示 GPU 时钟降速的原因。<br>nvidia_smi_command_exit_code: 上次抓取命令的退出代码。<br>nvidia_smi_compute_mode: 显示 GPU 的计算模式。<br>nvidia_smi_count: 显示 GPU 的数量。<br>nvidia_smi_display_active: 显示是否有活动的显示器连接到 GPU。<br>nvidia_smi_display_mode: 显示 GPU 的显示模式。<br>nvidia_smi_ecc_errors_corrected_*: 显示 ECC 错误纠正情况。<br>nvidia_smi_ecc_errors_uncorrected_*: 显示 ECC 未纠正错误情况。<br>nvidia_smi_ecc_mode_current: 当前 ECC 模式。<br>nvidia_smi_ecc_mode_pending: 待定 ECC 模式。<br>nvidia_smi_encoder_stats_*: 编码器的状态，如平均帧率，平均延迟，会话数等。<br>nvidia_smi_enforced_power_limit_watts: 强制执行的功耗限制（瓦特）。<br>nvidia_smi_gpu_info: GPU 信息，包括 GPU 的 UUID，名称，驱动模型，VBIOS版本，驱动版本等。<br>nvidia_smi_index: GPU 索引。<br>nvidia_smi_inforom_ecc: Inforom ECC 信息。<br>nvidia_smi_pcie_link_width_max: PCIe链接的最大宽度。<br>nvidia_smi_persistence_mode: 持久模式的状态。<br>nvidia_smi_power_default_limit_watts: 默认的功率限制，单位是瓦特。<br>nvidia_smi_power_draw_watts: 当前绘制的功率，单位是瓦特。<br>nvidia_smi_power_limit_watts: 设置的功率限制，单位是瓦特。<br>nvidia_smi_power_management: 电源管理的状态。<br>nvidia_smi_power_max_limit_watts: 最大的功率限制，单位是瓦特。<br>nvidia_smi_power_min_limit_watts: 最小的功率限制，单位是瓦特。<br>nvidia_smi_pstate: 当前的性能状态 (P-state)。<br>nvidia_smi_retired_pages_double_bit_count: 双位错误退役页面的数量。<br>nvidia_smi_retired_pages_pending: 待处理的退役页面数量。<br>nvidia_smi_retired_pages_single_bit_ecc_count: 单位ECC错误退役页面的数量。<br>nvidia_smi_serial: GPU的序列号。<br>nvidia_smi_temperature_gpu: GPU的温度。<br>nvidia_smi_temperature_memory: 内存的温度。<br>nvidia_smi_utilization_gpu_ratio: GPU利用率，单位是百分比。<br>nvidia_smi_utilization_memory_ratio: 内存利用率，单位是百分比。<br>process_cpu_seconds_total: 进程所消耗的总CPU时间，单位是秒。<br>process_max_fds: 进程所能打开的最大文件描述符数量。<br>process_open_fds: 进程当前打开的文件描述符数量。<br>process_resident_memory_bytes: 进程常驻内存的大小，单位是字节。<br>process_start_time_seconds: 进程开始时间，单位是自Unix纪元以来的秒数。<br>process_virtual_memory_bytes: 进程虚拟内存的大小，单位是字节。<br>process_virtual_memory_max_bytes: 进程最大虚拟内存的大小，单位是字节。<br>promhttp_metric_handler_requests_in_flight: 当前正在处理的抓取请求数量。<br>promhttp_metric_handler_requests_total: 所有已完成的抓取请求数量，按HTTP状态码分类。<br>nvidia_smi_pcie_link_width_current: 当前的PCIe链接宽度。<br>nvidia_smi_ecc_errors_corrected_aggregate_device_memory: 累计的设备内存已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_aggregate_dram: 累计的DRAM已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_aggregate_l1_cache: 累计的L1缓存已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_aggregate_l2_cache: 累计的L2缓存已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_aggregate_register_file: 累计的寄存器文件已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_aggregate_total: 累计的所有已纠正的ECC错误总数。<br>nvidia_smi_ecc_errors_corrected_volatile_device_memory: 易失性设备内存已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_volatile_dram: 易失性DRAM已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_volatile_l1_cache: 易失性L1缓存已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_volatile_l2_cache: 易失性L2缓存已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_volatile_register_file: 易失性寄存器文件已纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_corrected_volatile_total: 易失性所有已纠正的ECC错误总数。<br>nvidia_smi_ecc_errors_uncorrected_aggregate_cbu: 累计的CBU未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_aggregate_device_memory: 累计的设备内存未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_aggregate_dram: 累计的DRAM未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_aggregate_l1_cache: 累计的L1缓存未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_aggregate_l2_cache: 累计的L2缓存未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_aggregate_register_file: 累计的寄存器文件未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_aggregate_total: 累计的所有未纠正的ECC错误总数。<br>nvidia_smi_ecc_errors_uncorrected_volatile_cbu: 易失性CBU未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_volatile_device_memory: 易失性设备内存未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_volatile_dram: 易失性DRAM未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_volatile_l1_cache: 易失性L1缓存未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_volatile_l2_cache: 易失性L2缓存未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_volatile_register_file: 易失性寄存器文件未纠正的ECC错误数量。<br>nvidia_smi_ecc_errors_uncorrected_volatile_total: 易失性所有未纠正的ECC错误总数。<br>nvidia_smi_ecc_mode_current: 当前的ECC模式。<br>nvidia_smi_ecc_mode_pending: 待设置的ECC模式。<br>nvidia_smi_encoder_stats_average_fps: 编码器的平均帧率。<br>nvidia_smi_encoder_stats_average_latency: 编码器的平均延迟。<br>nvidia_smi_encoder_stats_session_count: 编码器的会话数量。<br>nvidia_smi_enforced_power_limit_watts: 实施的功率限制，单位是瓦特。<br>nvidia_smi_gpu_info: GPU信息，包括GPU的UUID，名称，驱动模型，VBIOS版本，驱动版本等。<br>nvidia_smi_index: GPU索引。<br>nvidia_smi_inforom_ecc: Inforom ECC信息。<br>nvidia_smi_inforom_oem: Inforom OEM信息。<br>nvidia_smi_memory_free_bytes: 空闲内存，单位是字节。<br>nvidia_smi_memory_total_bytes: 总内存，单位是字节。<br>nvidia_smi_memory_used_bytes: 已使用的内存，单位是字节。<br>nvidia_smi_pci_bus: PCI总线信息。<br>nvidia_smi_pci_device: PCI设备信息。<br>nvidia_smi_pci_device_id: PCI设备ID。<br>nvidia_smi_pci_domain: PCI领域信息。<br>nvidia_smi_pci_sub_device_id: PCI子设备ID。<br>nvidia_smi_pcie_link_gen_current: 当前的PCIe链接生成。<br>nvidia_smi_pcie_link_gen_max: PCIe链接的最大生成。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>gpu-export</title>
      <link href="/2024/11/08/gpu-export/"/>
      <url>/2024/11/08/gpu-export/</url>
      
        <content type="html"><![CDATA[<p>gpu-exporter+prometheus实现gpu监控</p><p>目录</p><ul><li>gpu-exporter+prometheus实现gpu监控</li><li>一、在gpu服务器上部署nvidia_gpu_exporter</li><li>1、获取nvidia_gpu_exporter</li><li>2、运行nvidia_gpu_exporter</li><li>3、检测监控数据</li><li>二、接入prometheus监控</li><li>三、常用监控指标</li><li>四、metrics接口信息示例</li></ul><p>gpu-exporter+prometheus实现gpu监控<br>本文档基于开源项目nvidia_gpu_exporter实现gpu监控<br>一、在gpu服务器上部署nvidia_gpu_exporter<br>1、获取nvidia_gpu_exporter<br>wget <a href="https://github.com/utkuozdemir/nvidia_gpu_exporter/releases/download/v1.2.0/nvidia_gpu_exporter_1.2.0_linux_x86_64.tar.gz">https://github.com/utkuozdemir/nvidia_gpu_exporter/releases/download/v1.2.0/nvidia_gpu_exporter_1.2.0_linux_x86_64.tar.gz</a><br>2、运行nvidia_gpu_exporter<br>tar xf nvidia_gpu_exporter_1.2.0_linux_x86_64.tar.gz mv nvidia_gpu_exporter &#x2F;usr&#x2F;local&#x2F;gpu-exporter&#x2F;nvidia_gpu_exporter &#x2F;usr&#x2F;local&#x2F;gpu-exporter&#x2F;nvidia_gpu_exporter &amp;<br>3、检测监控数据<br>项目运行后会自动监听:9835端口<br>尝试curl本机来查看是否正常获取到监控数据<br>curl localhost:9835&#x2F;metrics<br>二、接入prometheus监控<br>在prometheus.yml中添加exporter地址</p><ul><li>job_name: gpu-exporter  static_configs:  - targets: [‘192.168.2.23:9835’]    lables:      gpu: nvidia-4090      app: gpu-exporter  - targets: [‘192.168.2.26:9835’]    lables:      gpu: nvidia-4080      app: gpu-exporter<br>三、常用监控指标<br>指标名含义nvidia_smi_utilization_gpu_ratioGPU使用率nvidia_smi_memory_used_bytesGPU显存使用量nvidia_smi_memory_total_bytesGPU显存总量nvidia_smi_temperature_gpuGPU温度<br>Grafana dashboard</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>cpu指标</title>
      <link href="/2024/10/21/cpu%E6%8C%87%E6%A0%87/"/>
      <url>/2024/10/21/cpu%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<p>当 CPU 使用率高时，通常意味着系统的计算资源被大量占用。为了进一步理解 CPU 高使用率的情况，以下是一些关键指标及其解释，这些指标可以通过工具如 top、htop、mpstat 等获得。</p><ol><li>CPU 使用率的分类<br>CPU 使用率通常按不同的时间类型进行分类：</li></ol><ul><li>us<br> (user CPU usage)：用户空间的 CPU 使用时间，表示处理用户进程（非内核进程）的时间。包括运行应用程序、服务等。例如，运行一个 Python 程序时，它使用的 CPU 时间属于用户 CPU 时间。</li><li>高 us 时间：意味着用户态的程序占用了大量 CPU 资源，通常是由计算密集型任务引起的，如编译、压缩或运行计算密集型的服务（如数据库、Web 服务等）。</li><li>sy<br> (system CPU usage)：系统空间的 CPU 使用时间，表示内核态的时间。这部分时间主要用于执行操作系统内核中的代码，处理系统调用、硬件中断等。</li><li>高 sy 时间：意味着内核操作占用了大量 CPU，可能与频繁的系统调用、进程调度、I&#x2F;O 操作或设备驱动程序有关。</li><li>ni<br> (nice CPU usage)：用于被调整了优先级的进程，通常是那些在后台运行并且被降低优先级的进程。</li><li>高 ni 时间：表示低优先级任务在后台占用了 CPU 时间，可能是一些批处理任务或低优先级的进程。</li><li>id<br> (idle time)：CPU 处于空闲的时间。通常越低越说明 CPU 负载越高。</li><li>低 id 时间：意味着系统负载较高，CPU 几乎没有空闲时间。</li><li>wa<br> (iowait)：等待 I&#x2F;O 操作完成的 CPU 时间。I&#x2F;O 操作指的是磁盘或网络等设备的输入输出操作。</li><li>高 wa 时间：意味着系统中 CPU 等待磁盘或网络的 I&#x2F;O 操作完成。通常表示磁盘或网络是系统的瓶颈，而不是 CPU。</li><li>hi<br> (hardware interrupts)：CPU 被硬件中断占用的时间。</li><li>高 hi 时间：意味着设备或硬件中断（如网卡、硬盘控制器、外部设备等）占用了大量 CPU 资源。可能是硬件设备的故障、过多的中断请求等引起。</li><li>si<br> (software interrupts)：CPU 被软件中断占用的时间。</li><li>高 si 时间：表示处理软件中断所消耗的 CPU 时间。通常与网络流量、软中断等相关。</li><li>st<br> (steal time)：虚拟化环境中特有的时间，表示虚拟机等待主机分配 CPU 时间的时间。仅在虚拟机环境中会看到。</li><li>高 st 时间：意味着虚拟机没有获得足够的 CPU 资源，可能是主机资源不足或过度分配虚拟机造成的。</li></ul><ol start="2"><li>如何分析 CPU 高使用率<br>a. 用户态（us）时间高</li></ol><ul><li>如果 us 时间高，说明用户进程占用了大量的 CPU 资源。</li><li>原因可能是：</li><li>程序计算量很大（如数据处理、加密计算）。</li><li>代码运行效率低，存在性能瓶颈（如死循环或算法复杂度问题）。</li><li>解决办法：优化程序、检查并行任务是否过多、调整负载。<br>b. 系统态（sy）时间高</li><li>如果 sy 时间高，说明内核态进程占用了大量 CPU 时间。</li><li>原因可能是：</li><li>频繁的系统调用或 I&#x2F;O 请求（如大量磁盘读写、网络传输）。</li><li>系统驱动或服务故障。</li><li>解决办法：优化 I&#x2F;O 操作、减少系统调用、检查内核模块或驱动是否有问题。<br>c. 等待 I&#x2F;O（wa）时间高</li><li>如果 wa 时间高，说明 CPU 大部分时间在等待磁盘或网络等 I&#x2F;O 操作完成。</li><li>原因可能是：</li><li>磁盘或网络性能瓶颈。</li><li>频繁的磁盘读写或网络请求。</li><li>解决办法：优化磁盘使用，升级硬件，使用更快的存储设备，或者分散 I&#x2F;O 操作。<br>d. 硬件中断（hi）时间高</li><li>如果 hi 时间高，说明硬件中断频繁导致 CPU 资源被占用。</li><li>原因可能是：</li><li>硬件设备或驱动有问题，如网卡、硬盘控制器等。</li><li>解决办法：检查硬件设备，更新驱动程序，检查是否有硬件故障。<br>e. 软件中断（si）时间高</li><li>如果 si 时间高，说明大量的软件中断导致了 CPU 使用率增加。</li><li>原因可能是：</li><li>高网络流量、频繁的软中断（如大量数据包处理）。</li><li>解决办法：优化网络服务，使用硬件加速（如硬件防火墙、网络加速器）。<br>f. 虚拟化环境中（st）偷窃时间高</li><li>如果 st 时间高，说明虚拟机没有得到足够的 CPU 资源。</li><li>原因可能是：</li><li>主机 CPU 资源过度分配，虚拟机争抢 CPU 时间。</li><li>解决办法：调整虚拟机分配的资源或增加主机 CPU。</li></ul><ol start="3"><li>如何监控 CPU 高使用率</li></ol><ul><li>top 或 htop：查看整体 CPU 使用率、用户态和系统态的 CPU 时间。</li><li>mpstat：监控多核 CPU 的使用情况，命令 mpstat -P ALL 显示每个 CPU 核心的使用详情。</li><li>perf：用来做 CPU 性能分析，查找热点函数和进程，分析详细的 CPU 使用情况。</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>atop</title>
      <link href="/2024/10/21/atop/"/>
      <url>/2024/10/21/atop/</url>
      
        <content type="html"><![CDATA[<p>atop 是一个高级的系统监控工具，类似于 top，但功能更为强大。它不仅能监控 CPU、内存、磁盘、网络等的使用情况，还能保存历史记录以便以后查看。它对性能瓶颈的分析尤其有用。</p><ol><li>安装 atop<br>不同的 Linux 发行版有不同的安装方式。<br>在 Ubuntu&#x2F;Debian 系统上：<br>bash复制代码sudo apt install atop<br>在 CentOS&#x2F;RedHat 系统上：<br>bash复制代码sudo yum install atop<br>在 Fedora 系统上：<br>bash复制代码sudo dnf install atop<br>在 Arch Linux 系统上：<br>bash复制代码sudo pacman -S atop</li><li>启动 atop<br>启动 atop 很简单，只需运行：<br>bash复制代码sudo atop<br>atop 会实时显示系统各项资源的使用情况，并每 10 秒刷新一次（默认刷新间隔）。可以通过命令行参数来定制其行为。</li><li>atop 显示的信息<br>顶部的全局信息：</li></ol><ul><li>PRC：显示系统上的进程信息，包括每秒创建的进程和上下文切换数量。</li><li>CPU：显示 CPU 使用情况。分为用户空间、系统空间、硬件中断和软件中断的 CPU 占用。</li><li>CPL：显示系统的负载（即 CPU 队列长度），包括 1、5 和 15 分钟的平均负载。</li><li>MEM：显示内存的总体使用情况，包括总内存、已使用内存、缓存、和交换区的使用情况。</li><li>SWP：显示交换分区（Swap）信息。</li><li>DSK：显示磁盘的 IO 信息，包括每秒读写的块数。</li><li>NET：显示网络的发送和接收数据。<br>每个进程的信息：</li><li>PID：进程的 ID。</li><li>THR：进程的线程数。</li><li>SYSCPU：进程使用的系统 CPU 时间。</li><li>USRCUP：进程使用的用户 CPU 时间。</li><li>VSS：虚拟内存使用量。</li><li>RSS：实际使用的物理内存。</li><li>RDDSK：进程从磁盘读取的字节数。</li><li>WRDSK：进程写入磁盘的字节数。</li><li>NET：进程的网络活动，包括每秒发送和接收的字节数。</li><li>ST：系统状态，D 代表不可中断睡眠，R 代表运行中，S 代表休眠，Z 代表僵尸进程。</li></ul><ol start="4"><li>常用参数</li></ol><ul><li>-r<br>：以原始模式查看历史数据。<br>bash复制代码sudo atop -r &#x2F;var&#x2F;log&#x2F;atop&#x2F;atop_YYYYMMDD</li><li>-w<br>：将系统状态写入日志文件，默认保存到 &#x2F;var&#x2F;log&#x2F;atop&#x2F;。<br>bash复制代码sudo atop -w &#x2F;var&#x2F;log&#x2F;atop&#x2F;atop.log 10<br>这会每 10 秒记录一次系统状态。</li><li>-d<br>：显示磁盘统计信息。<br>bash复制代码sudo atop -d</li><li>-m<br>：显示内存统计信息。<br>bash复制代码sudo atop -m</li><li>-n<br>：显示网络统计信息。<br>bash复制代码sudo atop -n</li><li>-s<br>：显示交换分区的使用情况。<br>bash复制代码sudo atop -s</li><li>-u<br>：显示用户 CPU 使用信息。<br>bash复制代码sudo atop -u</li><li>-p <PID><br>：只显示指定进程的状态。<br>bash复制代码sudo atop -p <PID></li><li>-c<br>：显示进程的命令行。<br>bash复制代码sudo atop -c</li></ul><ol start="5"><li><p>在日志模式下查看历史数据<br>如果 atop 被配置为记录日志，你可以通过以下命令查看历史数据：<br>bash复制代码sudo atop -r &#x2F;var&#x2F;log&#x2F;atop&#x2F;atop_YYYYMMDD</p></li><li><p>交互命令<br>当 atop 运行时，你可以按键切换不同的视图：</p></li></ol><ul><li>c：显示&#x2F;隐藏命令行参数。</li><li>d：显示磁盘使用情况。</li><li>n：显示网络使用情况。</li><li>m：显示内存使用情况。</li><li>t：按 CPU 使用率排序进程。</li><li>u：按用户 CPU 使用率排序进程。</li><li>q：退出 atop。</li></ul><ol start="7"><li>结合 cron 自动记录<br>你可以通过 cron 定期执行 atop 来保存系统性能的历史数据。编辑 crontab 文件：<br>bash复制代码sudo crontab -e</li></ol><p>添加一行：<br>bash复制代码*&#x2F;10 * * * * &#x2F;usr&#x2F;bin&#x2F;atop -a -w &#x2F;var&#x2F;log&#x2F;atop&#x2F;atop.log 600</p><p>这会每 10 分钟执行一次 atop，并保存系统状态到日志。<br>8. 总结<br>atop 是一个功能强大的性能监控工具，它不仅能够实时监控系统性能，还能保存数据以便日后分析。通过掌握其各种参数和交互命令，能够轻松地分析系统的性能瓶颈，尤其在 CPU、内存、磁盘 IO 和网络负载方面。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>cpu满载排查</title>
      <link href="/2024/10/21/cpu%E6%BB%A1%E8%BD%BD%E6%8E%92%E6%9F%A5/"/>
      <url>/2024/10/21/cpu%E6%BB%A1%E8%BD%BD%E6%8E%92%E6%9F%A5/</url>
      
        <content type="html"><![CDATA[<p>当你的 CPU 占用率达到 99% 或接近满载时，需要通过以下步骤进行分析，以找出根本原因并采取相应的措施。以下是详细的分析思路：</p><ol><li>实时监控 CPU 占用<br>首先，使用系统自带的监控工具，实时查看哪些进程或线程在消耗大量的 CPU 资源。<br>常用工具：</li></ol><ul><li>Linux&#x2F;Unix 系统：</li><li>top：实时显示所有进程的 CPU、内存占用。按 P 可以按 CPU 使用率排序。</li><li>htop：更为人性化的进阶工具，显示每个核心的使用情况，并提供更详细的进程信息。</li><li>iostat：可以显示 CPU 和 I&#x2F;O 的使用情况，帮助识别是否是 I&#x2F;O 密集型进程。</li><li>mpstat：查看多核 CPU 的负载情况，帮助确定 CPU 负载是否集中在某个核心。</li><li>Windows 系统：</li><li>任务管理器：按 Ctrl+Shift+Esc，可以查看进程的 CPU 使用情况，按 CPU 列排序，找到占用最多资源的进程。</li><li>资源监视器：提供更详细的 CPU 和线程信息。</li><li>MacOS：</li><li>Activity Monitor：类似任务管理器的工具，可以监控每个进程的 CPU 使用。<br>示例：<br>在 Linux 中，使用 top：<br>bash复制代码top</li></ul><p>然后按 P 进行按 CPU 使用排序，查看最耗资源的进程。<br>2. 查找占用 CPU 过高的进程<br>当确定某个进程的 CPU 占用过高后，可以通过以下方法进一步分析：<br>Linux 系统：</p><ul><li>ps 命令<br>：查找具体进程信息：<br>bash复制代码ps -eo pid,ppid,cmd,%mem,%cpu –sort&#x3D;-%cpu | head<br>这将列出前几名 CPU 占用最多的进程。</li><li>pidstat<br>：如果你已经知道哪个进程消耗了大量 CPU，可以使用 pidstat 查看进程的详细 CPU 使用情况：<br>bash复制代码pidstat -p <PID> 1</li></ul><p>这将每秒监控该进程的 CPU 使用。<br>Windows 系统：<br>使用任务管理器或资源监视器查看具体进程的 CPU 消耗，并找到相关进程的进程 ID (PID)。<br>3. 分析进程的行为</p><ul><li>查看进程是否陷入死循环：如果某个程序 CPU 使用率过高，可能是由于某段代码中的死循环或资源争用问题。这种问题在开发过程中较为常见，尤其是某个线程陷入了无限循环导致高 CPU 使用。</li><li>检查日志：查看相关进程的日志，看看是否有错误或警告信息，是否有反复执行某些操作的情况。</li><li>查找内存泄漏或资源争用：有时 CPU 使用率高是因为系统资源争用或内存泄漏，导致进程不停地进行内存回收。</li></ul><ol start="4"><li>分析线程<br>对于一些复杂的多线程应用（例如 web 服务器、数据库等），一个进程可能包含多个线程，每个线程的 CPU 占用情况不同。<br>Linux：</li></ol><ul><li>top 命令：<br>按 H 可以显示每个线程的使用情况。</li><li>perf 工具：<br>perf 是 Linux 下的强大性能分析工具，可以跟踪某个进程的性能，找出具体的 CPU 消耗来源。<br>bash复制代码perf top</li></ul><p>Windows：<br>使用资源监视器查看单个进程中的线程详细 CPU 消耗。<br>5. 深入分析代码或系统调用<br>如果你确定是某个进程或服务消耗了大量 CPU 资源，且无法直接通过日志找到问题，可以使用性能分析器来进一步分析。</p><ul><li><p>Linux 的<br>strace 工具：用于跟踪系统调用，查看哪些系统调用频繁执行，可能导致高 CPU 使用：<br>bash复制代码strace -p <PID></p></li><li><p>perf 事件采样<br>：用 perf record 记录一段时间的性能事件，之后用 perf report 分析报告，查看哪个函数或哪段代码占用了最多的 CPU 资源：<br>bash复制代码perf record -p <PID> – sleep 10<br>perf report</p></li><li><p>Windows 的性能分析器<br>：可以使用 Windows Performance Analyzer (WPA) 或 Visual Studio 自带的性能分析工具，找到具体的代码瓶颈。</p></li></ul><ol start="6"><li>确认是否 I&#x2F;O 或内存瓶颈引起的 CPU 高占用<br>在某些情况下，CPU 高占用并不一定完全是 CPU 问题，可能是 I&#x2F;O 或内存瓶颈导致：</li></ol><ul><li>I&#x2F;O 密集型任务：如果某些进程频繁执行磁盘读写操作，导致 I&#x2F;O 等待时间很长，CPU 可能处于忙等待状态。</li><li>内存不足：当系统内存不足时，系统可能频繁进行内存交换（swapping），这会导致 CPU 负载增加。<br>使用 iostat 或 vmstat 等工具检查是否有频繁的磁盘 I&#x2F;O 活动。</li></ul><ol start="7"><li>检查硬件问题<br>如果 CPU 长期保持高负载，可能还需要检查硬件问题：</li></ol><ul><li>检查是否有散热问题：如果 CPU 温度过高，系统可能会降低性能，导致风扇或其他硬件组件长时间高负载工作。使用 sensors（Linux）或第三方监控工具检查 CPU 温度。</li><li>硬件老化：老化的硬件组件（如硬盘、内存）可能导致系统性能下降，检查硬件健康状况。</li></ul><ol start="8"><li>优化解决方案<br>处理 CPU 占用 99% 的情况，可以考虑以下措施：</li></ol><ul><li>优化代码：如果是某个程序导致的，检查是否可以优化代码、减少死循环或多余的计算。</li><li>调整进程优先级：使用 nice 或 renice 调整进程的优先级，降低该进程对 CPU 资源的争用。</li><li>增加硬件资源：如果是系统资源瓶颈，考虑增加更多 CPU 或内存，提升系统性能。<br>通过这些步骤，你可以逐步排查和解决 CPU 高占用问题。</li></ul><ol><li>安装 strace<br>strace 是 Linux 下的系统调用跟踪工具，能够帮助你跟踪某个进程的系统调用。<br>在 Ubuntu&#x2F;Debian 系统上：<br>使用 apt 包管理器安装：<br>bash复制代码sudo apt update<br>sudo apt install strace</li></ol><p>在 RedHat&#x2F;CentOS&#x2F;Fedora 系统上：<br>使用 dnf 或 yum 安装：<br>bash复制代码sudo dnf install strace</p><p>或者：<br>bash复制代码sudo yum install strace</p><p>在 Arch Linux 系统上：<br>使用 pacman 安装：<br>bash复制代码sudo pacman -S strace</p><ol start="2"><li>安装 perf<br>perf 是 Linux 下的性能分析工具，能够帮助你跟踪和分析系统性能瓶颈。<br>在 Ubuntu&#x2F;Debian 系统上：<br>安装 linux-tools 包，这个包里包括 perf 工具：<br>bash复制代码sudo apt update<br>sudo apt install linux-tools-common linux-tools-$(uname -r)<br>在 RedHat&#x2F;CentOS&#x2F;Fedora 系统上：<br>使用 dnf 或 yum 安装：<br>bash复制代码sudo dnf install perf<br>或者：<br>bash复制代码sudo yum install perf<br>在 Arch Linux 系统上：<br>使用 pacman 安装：<br>bash复制代码sudo pacman -S perf</li><li>检查安装<br>安装完成后，可以运行以下命令，确保安装成功并检查版本：</li></ol><ul><li>strace：<br>bash复制代码strace -V</li><li>perf：<br>bash复制代码perf –version<br>安装完成后，你就可以使用 strace 和 perf 工具来进行系统调用和性能分析了。如果有任何问题，可以进一步调试和优化系统的性能。</li></ul>]]></content>
      
      
      <categories>
          
          <category> linux学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> cpu高 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linuxRAID</title>
      <link href="/2024/09/13/linuxRAID/"/>
      <url>/2024/09/13/linuxRAID/</url>
      
        <content type="html"><![CDATA[<p>系统中的软 RAID 和硬 RAID 是两种不同的 RAID (Redundant Array of Independent Disks) 实现方式，用于提高数据存储的性能、冗余和可靠性。它们的主要区别在于 RAID 的管理方式、性能和硬件依赖性。</p><ol><li>软 RAID (Software RAID)<br>软 RAID 是通过操作系统的软件来实现 RAID 功能的，无需专用的硬件 RAID 控制器。</li></ol><ul><li>实现方式<br>：软 RAID 依赖于操作系统的驱动程序和 CPU 来执行 RAID 逻辑。它通过软件层进行管理，常见的工具如 Linux 中的 mdadm 可以创建和管理软 RAID。</li><li>优点<br>：</li><li>成本低：无需专门的 RAID 硬件，使用现有的硬盘和 CPU 资源即可实现 RAID 功能。</li><li>灵活性高：几乎所有类型的 RAID（如 RAID 0、RAID 1、RAID 5、RAID 10 等）都可以通过软件配置，且与硬件无关。</li><li>易于配置：可以通过操作系统命令轻松管理 RAID 阵列。</li><li>缺点<br>：</li><li>性能较差：软 RAID 依赖系统的 CPU 来处理 RAID 操作，这会消耗一定的系统资源，特别是在高负载或复杂 RAID 类型（如 RAID 5、RAID 6）下。</li><li>受限于操作系统：需要操作系统支持，可能在不同的操作系统中实现不一致。</li></ul><ol start="2"><li>硬 RAID (Hardware RAID)<br>硬 RAID 是通过专用的 RAID 控制器（硬件卡）来管理和实现 RAID 功能。硬件 RAID 卡上通常有独立的处理器和内存，用于处理 RAID 操作。</li></ol><ul><li>实现方式<br>：硬 RAID 使用独立的 RAID 控制器管理所有 RAID 操作，这些控制器有自己的处理器，独立于系统 CPU，且可以处理磁盘之间的所有数据交互。</li><li>优点<br>：</li><li>性能更好：由于 RAID 操作由专用硬件处理，不会占用系统 CPU，因此性能更高，特别是在高负载环境下。</li><li>更好的数据保护：硬 RAID 卡通常带有电池备份和缓存功能，以防止数据丢失。</li><li>操作系统无关：硬件 RAID 对操作系统透明，操作系统只会看到一个逻辑磁盘，硬 RAID 在系统启动时即可生效。</li><li>缺点<br>：</li><li>成本高：需要购买专用的 RAID 控制器，硬 RAID 卡可能价格较高，特别是支持更多磁盘和高性能的卡。</li><li>兼容性问题：不同厂商的 RAID 控制器可能有不同的驱动程序和管理工具，存在兼容性问题。</li><li>维护复杂：硬 RAID 的设置和故障排查可能需要专门的工具和知识。</li></ul><ol start="3"><li>对比<br>特性软 RAID硬 RAID实现方式通过操作系统实现通过专用硬件控制器实现成本低，使用现有系统资源高，需要购买专用硬件性能依赖于 CPU 和系统资源高，专用处理器处理 RAID 逻辑系统资源占用高，占用 CPU 和内存低，不占用系统资源数据安全由操作系统和软件负责硬件控制器有额外的数据保护功能灵活性高，易于配置和更改较低，依赖硬件设置<br>总结</li></ol><ul><li>软 RAID 适用于对性能要求不高、预算有限的场景，或者当不需要额外硬件时。</li><li>硬 RAID 则适用于高性能、高可靠性、对数据保护有更高需求的场景，比如服务器或数据中心。</li></ul><p>RAID 是一种用于管理和组织多个硬盘的方法，以实现性能提升或数据冗余。不同的 RAID 级别提供不同的性能、数据保护和存储效率。下面简要介绍几种常见的 RAID 级别：</p><ol><li>RAID 0（条带化）<br>RAID 0 将数据分成块，然后在多个磁盘上并行存储。它没有冗余或数据保护机制，但可以显著提升读写速度。</li></ol><ul><li>数据保护：无</li><li>优点：高速的读写性能，尤其适合需要高吞吐量的应用程序。</li><li>缺点：没有数据冗余，任何一块磁盘损坏，整个阵列的数据都会丢失。</li><li>存储效率：100%（n 块磁盘可用 n 倍容量）</li></ul><ol start="2"><li>RAID 1（镜像）<br>RAID 1 是最简单的冗余形式。它将同一份数据完整地复制到两个或更多磁盘上。每个磁盘都保存完整的副本，因此具有较高的容错能力。</li></ol><ul><li>数据保护：非常高，只要有一个磁盘完好，数据就安全。</li><li>优点：高度的数据安全性，读取性能提升（因为可以同时从两个磁盘读取）。</li><li>缺点：存储效率低，存储成本较高，因为两个磁盘保存相同的数据。</li><li>存储效率：50%（n 块磁盘中仅有 n&#x2F;2 的容量可用）</li></ul><ol start="3"><li>RAID 3（带有奇偶校验的字节级条带化）<br>RAID 3 使用字节级条带化，并在一个专用磁盘上保存奇偶校验数据。每次写入操作会更新奇偶校验磁盘，以确保当数据磁盘故障时可以通过奇偶校验数据恢复数据。</li></ol><ul><li>数据保护：允许一个磁盘故障，数据仍可恢复。</li><li>优点：提供容错，写入性能较好，适合连续的大量数据传输。</li><li>缺点：奇偶校验磁盘成为单点瓶颈，写入时需要更新奇偶校验。</li><li>存储效率：(n-1)&#x2F;n（n 块磁盘，1 块用于奇偶校验）</li></ul><ol start="4"><li>RAID 5（带有奇偶校验的块级条带化）<br>RAID 5 是最常用的 RAID 级别之一，它使用块级条带化，并在多个磁盘上分布保存奇偶校验数据。与 RAID 3 不同，RAID 5 并不需要单独的奇偶校验磁盘，而是将奇偶校验块均匀分布在所有磁盘上。</li></ol><ul><li>数据保护：允许一个磁盘故障，数据仍可恢复。</li><li>优点：读写性能较好，提供冗余和较高的存储效率。</li><li>缺点：写入时需要计算和更新奇偶校验，写性能稍差，尤其是小文件写入。</li><li>存储效率：(n-1)&#x2F;n（n 块磁盘，1 块相当于用于奇偶校验）</li></ul><ol start="5"><li>RAID 6（带有双奇偶校验的块级条带化）<br>RAID 6 类似于 RAID 5，但它使用两个奇偶校验块，这使得它能够在任意两个磁盘同时故障时仍能恢复数据。奇偶校验数据分布在所有磁盘上。</li></ol><ul><li>数据保护：允许最多两个磁盘故障，数据仍可恢复。</li><li>优点：高度的数据安全性，尤其适合大容量磁盘阵列，双奇偶校验防止多块磁盘故障。</li><li>缺点：写入时的计算复杂度更高，写性能低于 RAID 5，特别是小文件写入时。</li><li>存储效率：(n-2)&#x2F;n（n 块磁盘，2 块用于奇偶校验）</li></ul><ol start="6"><li>RAID 10（RAID 1+0，镜像和条带化）<br>RAID 10 是 RAID 1 和 RAID 0 的组合。它先做 RAID 1（镜像），然后在多个镜像对上做 RAID 0（条带化）。RAID 10 提供了 RAID 0 的性能和 RAID 1 的冗余。</li></ol><ul><li>数据保护：允许每组 RAID 1 中一个磁盘故障，提供较高的数据冗余和容错能力。</li><li>优点：读取和写入性能都很好，容错能力高。</li><li>缺点：存储效率较低，磁盘数量必须为偶数，且存储效率为 50%。</li><li>存储效率：50%（n 块磁盘中仅有 n&#x2F;2 的容量可用）</li></ul><ol start="7"><li>RAID 50（RAID 5+0）<br>RAID 50 是 RAID 5 和 RAID 0 的组合，先做 RAID 5 再在多个 RAID 5 阵列上做 RAID 0。它结合了 RAID 5 的冗余和 RAID 0 的性能。</li></ol><ul><li>数据保护：允许每个 RAID 5 阵列中一个磁盘故障。</li><li>优点：提供 RAID 5 的冗余以及 RAID 0 的读写性能提升。</li><li>缺点：相比 RAID 5 需要更多磁盘，配置复杂度较高。</li><li>存储效率：依赖于 RAID 5 配置</li></ul><ol start="8"><li>RAID 60（RAID 6+0）<br>RAID 60 是 RAID 6 和 RAID 0 的组合，先做 RAID 6 再在多个 RAID 6 阵列上做 RAID 0，提供双重冗余和高性能。</li></ol><ul><li>数据保护：允许每个 RAID 6 阵列中最多两个磁盘故障。</li><li>优点：更高的数据安全性和可靠性，以及 RAID 0 提供的性能提升。</li><li>缺点：配置复杂度和成本较高，写性能会因为 RAID 6 的双奇偶校验受到影响。</li><li>存储效率：依赖于 RAID 6 配置<br>总结<br>不同的 RAID 级别适合不同的应用场景：</li><li>RAID 0：用于需要高性能但不关心数据安全性的场景。</li><li>RAID 1：适合需要高数据安全性，且存储容量要求不高的场景。</li><li>RAID 5 和 RAID 6：适合需要较高读写性能，同时需要数据冗余的企业环境。</li><li>RAID 10：适合需要高性能和高容错的高端应用，例如数据库或关键业务系统。<br>每种 RAID 级别在性能、数据安全和存储效率之间取得不同的平衡。选择适合的 RAID 类型应根据存储需求、可用的磁盘数量、性能要求和数据安全级别进行综合考虑。</li></ul><p>冗余度 是指在 RAID 等数据存储系统中，系统通过额外的磁盘或数据副本来保护数据的一种方式，确保在硬件故障（如磁盘损坏）时系统仍能继续运行并保持数据完整性。不同的 RAID 级别提供不同的冗余方式，主要通过数据镜像、奇偶校验等手段来实现。<br>冗余度的理解：</p><ul><li>高冗余度：表示系统具有更强的故障容忍能力，允许更多磁盘故障而不会丢失数据。例如，RAID 1（镜像）和 RAID 6（双奇偶校验）都提供较高的冗余度。</li><li>低冗余度：表示系统容忍磁盘故障的能力较弱，甚至没有冗余保护。比如 RAID 0 没有任何冗余，一块磁盘故障就会导致整个系统的数据丢失。<br>冗余度举例：</li><li>RAID 1（镜像）：每个磁盘都有一个完整的副本（镜像），因此冗余度为 1。也就是说，即使一块磁盘故障，仍然可以从镜像中恢复数据。</li><li>RAID 5：通过奇偶校验在多个磁盘上分布存储数据，冗余度允许一个磁盘故障，且能够通过奇偶校验恢复数据。</li><li>RAID 6：类似 RAID 5，但增加了双重奇偶校验，允许两个磁盘同时故障的情况下仍可恢复数据，冗余度更高。<br>热备盘 (Hot Spare Disk) 的概念：<br>热备盘 是一种专用磁盘，虽然它没有参与 RAID 的正常读写操作，但在 RAID 阵列中的某个磁盘发生故障时，它会自动接替故障的磁盘，成为 RAID 阵列的一部分，立即开始数据重建过程。这种机制可以大幅缩短故障恢复的时间，提升系统的可靠性。<br>热备盘的工作原理：<br>1.RAID 阵列中某个磁盘发生故障时，系统会自动检测到这个故障。<br>2.热备盘自动替换这个故障磁盘，接管其工作。<br>3.RAID 系统会开始重建数据，将原本损坏磁盘中的数据重建到热备盘上（利用镜像、奇偶校验等方法）。<br>4.系统在数据恢复后继续正常运行，无需人工干预。<br>热备盘的分类：</li><li>本地热备盘（Local Hot Spare）：仅为一个特定的 RAID 阵列服务，当该阵列中的某个磁盘故障时，热备盘会立即生效。</li><li>全局热备盘（Global Hot Spare）：可以服务于多个 RAID 阵列，当任何一个阵列的磁盘发生故障时，热备盘都会自动接替故障磁盘的工作。<br>冗余度与热备盘的关系：</li><li>冗余度 指的是 RAID 系统能够容忍的磁盘故障数量。例如 RAID 5 允许一个磁盘故障，RAID 6 允许两个磁盘故障。</li><li>热备盘 提高了 RAID 系统的自动故障恢复能力，但不影响冗余度。它的作用是在磁盘故障时，快速替代故障磁盘并启动数据重建，从而减少阵列暴露在“降低冗余度”的时间内。</li></ul>]]></content>
      
      
      <categories>
          
          <category> linux学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> raid </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker挂载本机目录</title>
      <link href="/2024/09/11/docker%E6%8C%82%E8%BD%BD%E6%9C%AC%E6%9C%BA%E7%9B%AE%E5%BD%95/"/>
      <url>/2024/09/11/docker%E6%8C%82%E8%BD%BD%E6%9C%AC%E6%9C%BA%E7%9B%AE%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h1 id="挂载主机目录"><a href="#挂载主机目录" class="headerlink" title="挂载主机目录"></a>挂载主机目录</h1><h2 id="挂载一个主机目录作为数据卷"><a href="#挂载一个主机目录作为数据卷" class="headerlink" title="挂载一个主机目录作为数据卷"></a>挂载一个主机目录作为数据卷</h2><p>使用 <code>--mount</code> 标记可以指定挂载一个本地主机的目录到容器中去。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run -d -P \</span></span><br><span class="line"><span class="language-bash">    --name web \</span></span><br><span class="line"><span class="language-bash">    <span class="comment"># -v /src/webapp:/usr/share/nginx/html \</span></span></span><br><span class="line"><span class="language-bash">    --mount <span class="built_in">type</span>=<span class="built_in">bind</span>,<span class="built_in">source</span>=/src/webapp,target=/usr/share/nginx/html \</span></span><br><span class="line"><span class="language-bash">    nginx:alpine</span></span><br></pre></td></tr></table></figure><p>上面的命令加载主机的 <code>/src/webapp</code> 目录到容器的 <code>/usr/share/nginx/html</code>目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，以前使用 <code>-v</code> 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 <code>--mount</code> 参数时如果本地目录不存在，Docker 会报错。</p><p>Docker 挂载主机目录的默认权限是 <code>读写</code>，用户也可以通过增加 <code>readonly</code> 指定为 <code>只读</code>。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run -d -P \</span></span><br><span class="line"><span class="language-bash">    --name web \</span></span><br><span class="line"><span class="language-bash">    <span class="comment"># -v /src/webapp:/usr/share/nginx/html:ro \</span></span></span><br><span class="line"><span class="language-bash">    --mount <span class="built_in">type</span>=<span class="built_in">bind</span>,<span class="built_in">source</span>=/src/webapp,target=/usr/share/nginx/html,<span class="built_in">readonly</span> \</span></span><br><span class="line"><span class="language-bash">    nginx:alpine</span></span><br></pre></td></tr></table></figure><p>加了 <code>readonly</code> 之后，就挂载为 <code>只读</code> 了。如果你在容器内 <code>/usr/share/nginx/html</code> 目录新建文件，会显示如下错误</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/share/nginx/html # touch new.txt</span><br><span class="line">touch: new.txt: Read-only file system</span><br></pre></td></tr></table></figure><h2 id="查看数据卷的具体信息"><a href="#查看数据卷的具体信息" class="headerlink" title="查看数据卷的具体信息"></a>查看数据卷的具体信息</h2><p>在主机里使用以下命令可以查看 <code>web</code> 容器的信息</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker inspect web</span></span><br></pre></td></tr></table></figure><p><code>挂载主机目录</code> 的配置信息在 “Mounts” Key 下面</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&quot;Mounts&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Type&quot;: &quot;bind&quot;,</span><br><span class="line">        &quot;Source&quot;: &quot;/src/webapp&quot;,</span><br><span class="line">        &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;,</span><br><span class="line">        &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">        &quot;RW&quot;: true,</span><br><span class="line">        &quot;Propagation&quot;: &quot;rprivate&quot;</span><br><span class="line">    &#125;</span><br><span class="line">],</span><br></pre></td></tr></table></figure><h2 id="挂载一个本地主机文件作为数据卷"><a href="#挂载一个本地主机文件作为数据卷" class="headerlink" title="挂载一个本地主机文件作为数据卷"></a>挂载一个本地主机文件作为数据卷</h2><p><code>--mount</code> 标记也可以从主机挂载单个文件到容器中</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run --<span class="built_in">rm</span> -it \</span></span><br><span class="line"><span class="language-bash">   <span class="comment"># -v $HOME/.bash_history:/root/.bash_history \</span></span></span><br><span class="line"><span class="language-bash">   --mount <span class="built_in">type</span>=<span class="built_in">bind</span>,<span class="built_in">source</span>=<span class="variable">$HOME</span>/.bash_history,target=/root/.bash_history \</span></span><br><span class="line"><span class="language-bash">   ubuntu:18.04 \</span></span><br><span class="line"><span class="language-bash">   bash</span></span><br><span class="line"></span><br><span class="line">root@2affd44b4667:/# history</span><br><span class="line">1  ls</span><br><span class="line">2  diskutil list</span><br></pre></td></tr></table></figure><p>这样就可以记录在容器输入过的命令了。</p>]]></content>
      
      
      <categories>
          
          <category> docker学习,mount </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> mount </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker数据卷</title>
      <link href="/2024/09/11/docker%E6%95%B0%E6%8D%AE%E5%8D%B7/"/>
      <url>/2024/09/11/docker%E6%95%B0%E6%8D%AE%E5%8D%B7/</url>
      
        <content type="html"><![CDATA[<h1 id="数据卷"><a href="#数据卷" class="headerlink" title="数据卷"></a>数据卷</h1><p>&#96;数据卷是一个可供一个或多个容器使用的特殊目录，它绕过 UnionFS，可以提供很多有用的特性：</p><ul><li>&#96;数据卷可以在容器之间共享和重用</li><li>对数据卷的修改会立马生效</li><li>对数据卷的更新，不会影响镜像</li><li>&#96;数据卷默认会一直存在，即使容器被删除</li></ul><blockquote><p>注意：&#96;数据卷的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。</p></blockquote><h2 id="创建一个数据卷"><a href="#创建一个数据卷" class="headerlink" title="创建一个数据卷"></a>创建一个数据卷</h2><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker volume create my-vol</span></span><br></pre></td></tr></table></figure><p>查看所有的 <code>数据卷</code></p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker volume <span class="built_in">ls</span></span></span><br><span class="line"></span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line">local               my-vol</span><br></pre></td></tr></table></figure><p>在主机里使用以下命令可以查看指定数据卷的信息</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker volume inspect my-vol</span></span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Driver&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;,</span><br><span class="line">        &quot;Name&quot;: &quot;my-vol&quot;,</span><br><span class="line">        &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="启动一个挂载数据卷的容器"><a href="#启动一个挂载数据卷的容器" class="headerlink" title="启动一个挂载数据卷的容器"></a>启动一个挂载数据卷的容器</h2><p>在用 <code>docker run</code> 命令的时候，使用 <code>--mount</code> 标记来将 <code>数据卷</code> 挂载到容器里。在一次 <code>docker run</code> 中可以挂载多个 <code>数据卷</code>。</p><p>下面创建一个名为 <code>web</code> 的容器，并加载一个 <code>数据卷</code> 到容器的 <code>/usr/share/nginx/html</code> 目录。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run -d -P \</span></span><br><span class="line"><span class="language-bash">    --name web \</span></span><br><span class="line"><span class="language-bash">    <span class="comment"># -v my-vol:/usr/share/nginx/html \</span></span></span><br><span class="line"><span class="language-bash">    --mount <span class="built_in">source</span>=my-vol,target=/usr/share/nginx/html \</span></span><br><span class="line"><span class="language-bash">    nginx:alpine</span></span><br></pre></td></tr></table></figure><h2 id="查看数据卷的具体信息"><a href="#查看数据卷的具体信息" class="headerlink" title="查看数据卷的具体信息"></a>查看数据卷的具体信息</h2><p>在主机里使用以下命令可以查看 <code>web</code> 容器的信息</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker inspect web</span></span><br></pre></td></tr></table></figure><p><code>数据卷</code> 信息在 “Mounts” Key 下面</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;Mounts&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Type&quot;: &quot;volume&quot;,</span><br><span class="line">        &quot;Name&quot;: &quot;my-vol&quot;,</span><br><span class="line">        &quot;Source&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;,</span><br><span class="line">        &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">        &quot;RW&quot;: true,</span><br><span class="line">        &quot;Propagation&quot;: &quot;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">],</span><br></pre></td></tr></table></figure><h2 id="删除数据卷"><a href="#删除数据卷" class="headerlink" title="删除数据卷"></a>删除数据卷</h2><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker volume <span class="built_in">rm</span> my-vol</span></span><br></pre></td></tr></table></figure><p><code>数据卷</code> 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 <code>数据卷</code>，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 <code>数据卷</code>。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 <code>docker rm -v</code> 这个命令。</p><p>无主的数据卷可能会占据很多空间，要清理请使用以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker volume prune</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> docker学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker仓库</title>
      <link href="/2024/09/11/docker%E4%BB%93%E5%BA%93/"/>
      <url>/2024/09/11/docker%E4%BB%93%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<h1 id="私有仓库"><a href="#私有仓库" class="headerlink" title="私有仓库"></a>私有仓库</h1><p>有时候使用 Docker Hub 这样的公共仓库可能不方便，用户可以创建一个本地仓库供私人使用。</p><p>本节介绍如何使用本地仓库。</p><p><a href="https://docs.docker.com/registry/"><code>docker-registry</code></a> 是官方提供的工具，可以用于构建私有的镜像仓库。本文内容基于 <a href="https://github.com/docker/distribution"><code>docker-registry</code></a> v2.x 版本。</p><h2 id="安装运行-docker-registry"><a href="#安装运行-docker-registry" class="headerlink" title="安装运行 docker-registry"></a>安装运行 docker-registry</h2><h3 id="容器运行"><a href="#容器运行" class="headerlink" title="容器运行"></a>容器运行</h3><p>你可以使用官方 <code>registry</code> 镜像来运行。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run -d -p 5000:5000 --restart=always --name registry registry</span></span><br></pre></td></tr></table></figure><p>这将使用官方的 <code>registry</code> 镜像来启动私有仓库。默认情况下，仓库会被创建在容器的 <code>/var/lib/registry</code> 目录下。你可以通过 <code>-v</code> 参数来将镜像文件存放在本地的指定路径。例如下面的例子将上传的镜像放到本地的 <code>/opt/data/registry</code> 目录。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run -d \</span></span><br><span class="line"><span class="language-bash">    -p 5000:5000 \</span></span><br><span class="line"><span class="language-bash">    -v /opt/data/registry:/var/lib/registry \</span></span><br><span class="line"><span class="language-bash">    registry</span></span><br></pre></td></tr></table></figure><h2 id="在私有仓库上传、搜索、下载镜像"><a href="#在私有仓库上传、搜索、下载镜像" class="headerlink" title="在私有仓库上传、搜索、下载镜像"></a>在私有仓库上传、搜索、下载镜像</h2><p>创建好私有仓库之后，就可以使用 <code>docker tag</code> 来标记一个镜像，然后推送它到仓库。例如私有仓库地址为 <code>127.0.0.1:5000</code>。</p><p>先在本机查看已有的镜像。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker image <span class="built_in">ls</span></span></span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span><br><span class="line">ubuntu                            latest              ba5877dc9bec        6 weeks ago         192.7 MB</span><br></pre></td></tr></table></figure><p>使用 <code>docker tag</code> 将 <code>ubuntu:latest</code> 这个镜像标记为 <code>127.0.0.1:5000/ubuntu:latest</code>。</p><p>格式为 <code>docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]</code>。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker tag ubuntu:latest 127.0.0.1:5000/ubuntu:latest</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker image <span class="built_in">ls</span></span></span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span><br><span class="line">ubuntu                            latest              ba5877dc9bec        6 weeks ago         192.7 MB</span><br><span class="line">127.0.0.1:5000/ubuntu:latest      latest              ba5877dc9bec        6 weeks ago         192.7 MB</span><br></pre></td></tr></table></figure><p>使用 <code>docker push</code> 上传标记的镜像。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker push 127.0.0.1:5000/ubuntu:latest</span></span><br><span class="line">The push refers to repository [127.0.0.1:5000/ubuntu]</span><br><span class="line">373a30c24545: Pushed</span><br><span class="line">a9148f5200b0: Pushed</span><br><span class="line">cdd3de0940ab: Pushed</span><br><span class="line">fc56279bbb33: Pushed</span><br><span class="line">b38367233d37: Pushed</span><br><span class="line">2aebd096e0e2: Pushed</span><br><span class="line">latest: digest: sha256:fe4277621f10b5026266932ddf760f5a756d2facd505a94d2da12f4f52f71f5a size: 1568</span><br></pre></td></tr></table></figure><p>用 <code>curl</code> 查看仓库中的镜像。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 127.0.0.1:5000/v2/_catalog</span></span><br><span class="line">&#123;&quot;repositories&quot;:[&quot;ubuntu&quot;]&#125;</span><br></pre></td></tr></table></figure><p>这里可以看到 <code>&#123;&quot;repositories&quot;:[&quot;ubuntu&quot;]&#125;</code>，表明镜像已经被成功上传了。</p><p>先删除已有镜像，再尝试从私有仓库中下载这个镜像。</p><p>复制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker image <span class="built_in">rm</span> 127.0.0.1:5000/ubuntu:latest</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker pull 127.0.0.1:5000/ubuntu:latest</span></span><br><span class="line">Pulling repository 127.0.0.1:5000/ubuntu:latest</span><br><span class="line">ba5877dc9bec: Download complete</span><br><span class="line">511136ea3c5a: Download complete</span><br><span class="line">9bad880da3d2: Download complete</span><br><span class="line">25f11f5fb0cb: Download complete</span><br><span class="line">ebc34468f71d: Download complete</span><br><span class="line">2318d26665ef: Download complete</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker image <span class="built_in">ls</span></span></span><br><span class="line">REPOSITORY                         TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span><br><span class="line">127.0.0.1:5000/ubuntu:latest       latest              ba5877dc9bec        6 weeks ago         192.7 MB</span><br></pre></td></tr></table></figure><h2 id="配置非-https-仓库地址"><a href="#配置非-https-仓库地址" class="headerlink" title="配置非 https 仓库地址"></a>配置非 https 仓库地址</h2><p>如果你不想使用 <code>127.0.0.1:5000</code> 作为仓库地址，比如想让本网段的其他主机也能把镜像推送到私有仓库。你就得把例如 <code>192.168.199.100:5000</code> 这样的内网地址作为私有仓库地址，这时你会发现无法成功推送镜像。</p><p>这是因为 Docker 默认不允许非 <code>HTTPS</code> 方式推送镜像。我们可以通过 Docker 的配置选项来取消这个限制，或者查看下一节配置能够通过 <code>HTTPS</code> 访问的私有仓库。</p><h3 id="Ubuntu-16-04-Debian-8-centos-7"><a href="#Ubuntu-16-04-Debian-8-centos-7" class="headerlink" title="Ubuntu 16.04+, Debian 8+, centos 7"></a>Ubuntu 16.04+, Debian 8+, centos 7</h3><p>对于使用 <code>systemd</code> 的系统，请在 <code>/etc/docker/daemon.json</code> 中写入如下内容（如果文件不存在请新建该文件）</p><p>复制</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;registry-mirrors&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;https://hub-mirror.c.163.com&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;https://mirror.baidubce.com&quot;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;insecure-registries&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;192.168.199.100:5000&quot;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><blockquote><p>注意：该文件必须符合 <code>json</code> 规范，否则 Docker 将不能启动。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> docker学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keepalived：Nginx高可用的实现及抢占式与非抢占模式详解</title>
      <link href="/2024/08/12/keepalived/"/>
      <url>/2024/08/12/keepalived/</url>
      
        <content type="html"><![CDATA[<h1 id="Keepalived：Nginx高可用的实现及抢占式与非抢占模式详解"><a href="#Keepalived：Nginx高可用的实现及抢占式与非抢占模式详解" class="headerlink" title="Keepalived：Nginx高可用的实现及抢占式与非抢占模式详解"></a>Keepalived：Nginx高可用的实现及抢占式与非抢占模式详解</h1><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>Keepalived 是一种用于实现高可用性的工具，通过提供虚拟 IP（VIP），允许两个或多个服务器共享同一个 IP 地址，当一台服务器故障时，另一台服务器可以立即接管，确保服务的持续可用性。</p><h2 id="2-Keepalived-安装"><a href="#2-Keepalived-安装" class="headerlink" title="2. Keepalived 安装"></a>2. Keepalived 安装</h2><p>在 CentOS&#x2F;RHEL 系统上，可以通过以下命令安装 Keepalived：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install keepalived -y</span><br></pre></td></tr></table></figure><h2 id="3-Keepalived抢占式配置"><a href="#3-Keepalived抢占式配置" class="headerlink" title="3. Keepalived抢占式配置"></a>3. Keepalived抢占式配置</h2><h3 id="3-1-Keepalived抢占式MASTER配置"><a href="#3-1-Keepalived抢占式MASTER配置" class="headerlink" title="3.1 Keepalived抢占式MASTER配置"></a>3.1 Keepalived抢占式MASTER配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">vrrp_script chk_nginx &#123;</span><br><span class="line">  script <span class="string">&quot;/usr/local/bin/check_nginx.sh&quot;</span></span><br><span class="line">  interval 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">  state MASTER</span><br><span class="line">  interface eth0</span><br><span class="line">  virtual_router_id 51</span><br><span class="line">  priority 100</span><br><span class="line">  advert_int 1</span><br><span class="line">  authentication &#123;</span><br><span class="line">    auth_type PASS</span><br><span class="line">    auth_pass 12345</span><br><span class="line">  &#125;</span><br><span class="line">  virtual_ipaddress &#123;</span><br><span class="line">    192.168.0.100</span><br><span class="line">  &#125;</span><br><span class="line">  track_script &#123;</span><br><span class="line">    chk_nginx</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment"># 默认抢占模式，不需要额外设置</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-Keepalived抢占式BACKUP配置"><a href="#3-2-Keepalived抢占式BACKUP配置" class="headerlink" title="3.2 Keepalived抢占式BACKUP配置"></a>3.2 Keepalived抢占式BACKUP配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">vrrp_script chk_nginx &#123;</span><br><span class="line">  script <span class="string">&quot;/usr/local/bin/check_nginx.sh&quot;</span></span><br><span class="line">  interval 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">  state BACKUP</span><br><span class="line">  interface eth0</span><br><span class="line">  virtual_router_id 51</span><br><span class="line">  priority 90</span><br><span class="line">  advert_int 1</span><br><span class="line">  authentication &#123;</span><br><span class="line">    auth_type PASS</span><br><span class="line">    auth_pass 12345</span><br><span class="line">  &#125;</span><br><span class="line">  virtual_ipaddress &#123;</span><br><span class="line">    192.168.0.100</span><br><span class="line">  &#125;</span><br><span class="line">  track_script &#123;</span><br><span class="line">    chk_nginx</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment"># 默认抢占模式，不需要额外设置</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-Keepalived非抢占式配置"><a href="#4-Keepalived非抢占式配置" class="headerlink" title="4 Keepalived非抢占式配置"></a>4 Keepalived非抢占式配置</h2><h2 id="4-1-Keepalived非抢占式MASTER配置"><a href="#4-1-Keepalived非抢占式MASTER配置" class="headerlink" title="4.1 Keepalived非抢占式MASTER配置"></a>4.1 Keepalived非抢占式MASTER配置</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">  state BACKUP</span><br><span class="line">  interface eth0</span><br><span class="line">  virtual_router_id 51</span><br><span class="line">  priority 100</span><br><span class="line">  advert_int 1</span><br><span class="line">  authentication &#123;</span><br><span class="line">    auth_type PASS</span><br><span class="line">    auth_pass 12345</span><br><span class="line">  &#125;</span><br><span class="line">  virtual_ipaddress &#123;</span><br><span class="line">    192.168.0.100</span><br><span class="line">  &#125;</span><br><span class="line">  nopreempt  <span class="comment"># 禁用抢占模式</span></span><br><span class="line">  track_script &#123;</span><br><span class="line">    chk_nginx</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-2-Keepalived非抢占式BACKUP配置"><a href="#4-2-Keepalived非抢占式BACKUP配置" class="headerlink" title="4.2 Keepalived非抢占式BACKUP配置"></a>4.2 Keepalived非抢占式BACKUP配置</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">  state BACKUP</span><br><span class="line">  interface eth0</span><br><span class="line">  virtual_router_id 51</span><br><span class="line">  priority 90</span><br><span class="line">  advert_int 1</span><br><span class="line">  authentication &#123;</span><br><span class="line">    auth_type PASS</span><br><span class="line">    auth_pass 12345</span><br><span class="line">  &#125;</span><br><span class="line">  virtual_ipaddress &#123;</span><br><span class="line">    192.168.0.100</span><br><span class="line">  &#125;</span><br><span class="line">  nopreempt  <span class="comment"># 禁用抢占模式</span></span><br><span class="line">  track_script &#123;</span><br><span class="line">    chk_nginx</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="5-启用并启动-Keepalived"><a href="#5-启用并启动-Keepalived" class="headerlink" title="5. 启用并启动 Keepalived"></a>5. 启用并启动 Keepalived</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl start keepalived</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> keepalived</span><br></pre></td></tr></table></figure><h2 id="6-测试配置"><a href="#6-测试配置" class="headerlink" title="6. 测试配置"></a>6. 测试配置</h2><h3 id="6-1-故障转移测试"><a href="#6-1-故障转移测试" class="headerlink" title="6.1 故障转移测试"></a>6.1 故障转移测试</h3><p>   在主节点上停止 Nginx：sudo systemctl stop nginx。<br>   检查 VIP 是否转移到备用节点。</p><h3 id="6-2-恢复测试"><a href="#6-2-恢复测试" class="headerlink" title="6.2 恢复测试"></a>6.2 恢复测试</h3><p>   重新启动主节点上的 Nginx：sudo systemctl start nginx。<br>   检查 VIP 是否回到主节点（针对抢占模式）。</p><h2 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h2><p>   通过 Keepalived，您可以实现高可用的 Nginx 集群。在抢占式模式下，主节点恢复后会重新获得 VIP，而在非抢占模式下，VIP 将继续保持在备节点，直到其停止运行。根据业务需求选择合适的模式，确保系统的高可用性和稳定性。</p>]]></content>
      
      
      <categories>
          
          <category> 基础设施 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keepalived </tag>
            
            <tag> Nginx </tag>
            
            <tag> 高可用性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/08/06/hello-world/"/>
      <url>/2024/08/06/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
